{"cells": [{"cell_type": "markdown", "id": "6f16d094", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<hr style=\"height: 1px;\">\n", "<i>This notebook was authored by the 8.S50x Course Team, Copyright 2022 MIT All Rights Reserved.</i>\n", "<hr style=\"height: 1px;\">\n", "<br>\n", "\n", "<h1>Lesson 6: Confidence</h1>\n"]}, {"cell_type": "markdown", "id": "e2ec7aa8", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_6_0'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L6.0 Overview</h2>\n"]}, {"cell_type": "markdown", "id": "005484fa", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<h3>Navigation</h3>\n", "\n", "<table style=\"width:100%\">\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_6_1\">L6.1 Introduction to Confidence Intervals</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_6_1\">L6.1 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_6_2\">L6.2 z-Scores and Confidence Intervals for Other Distributions</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_6_2\">L6.2 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_6_3\">L6.3 Another Example and Rules of Significance</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_6_3\">L6.3 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_6_4\">L6.4 Moments of Distributions and Mapping</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_6_4\">L6.4 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_6_5\">L6.5 Monte Carlo Integration</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_6_5\">L6.5 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_6_6\">L6.6 Returning to Fitting Supernova Data</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_6_6\">L6.6 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_6_7\">L6.7 Fitting with a More Accurate Model</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_6_7\">L6.7 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_6_8\">L6.8 Fit to Full Cosmological Model</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_6_8\">L6.8 Exercises</a></td>\n", "    </tr>\n", "</table>\n", "\n"]}, {"cell_type": "markdown", "id": "61244edd", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<h3>Importing Data (Colab Only)</h3>\n", "\n", "If you are in a Google Colab environment, run the cell below to import the data for this notebook. Otherwise, if you have downloaded the course repository, you do not have to run the cell below.\n", "\n", "See the source and attribution information below:\n", "\n", ">data: data/L04/sn_z_mu_dmu_plow_union2.1.txt <br>\n", ">source: http://supernova.lbl.gov/Union/, https://arxiv.org/abs/1105.3470 <br>\n", ">attribution: The Supernova Cosmology Project, arXiv:1105.3470v1 <br>\n", ">license type: https://arxiv.org/licenses/nonexclusive-distrib/1.0/license.html <br>"]}, {"cell_type": "code", "execution_count": null, "id": "014547bb", "metadata": {"tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L6.0-runcell00\n", "\n", "#importing data from git repository\n", "\n", "!git init\n", "!git remote add -f origin https://github.com/mitx-8s50/nb_LEARNER/\n", "!git config core.sparseCheckout true\n", "!echo 'data/L04' >> .git/info/sparse-checkout\n", "!git pull origin main"]}, {"cell_type": "code", "execution_count": null, "id": "2b06c9e9", "metadata": {"tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L6.0-runcell01\n", "\n", "!pip install lmfit"]}, {"cell_type": "code", "execution_count": null, "id": "45ae60a9", "metadata": {"tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L6.0-runcell02\n", "\n", "import numpy as np                #https://numpy.org/doc/stable/\n", "from scipy import stats           #https://docs.scipy.org/doc/scipy/reference/stats.html\n", "from scipy import optimize as opt #https://docs.scipy.org/doc/scipy/reference/optimize.html\n", "import matplotlib.pyplot as plt   #https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.html\n", "import math                       #https://docs.python.org/3/library/math.html\n", "import csv                        #https://docs.python.org/3/library/csv.html\n", "import lmfit                      #https://lmfit.github.io/lmfit-py/ "]}, {"cell_type": "code", "execution_count": null, "id": "7663d1de", "metadata": {"tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L6.0-runcell03\n", "\n", "#set plot resolution\n", "%config InlineBackend.figure_format = 'retina'\n", "\n", "#set default figure parameters\n", "plt.rcParams['figure.figsize'] = (9,6)\n", "\n", "medium_size = 12\n", "large_size = 15\n", "\n", "plt.rc('font', size=medium_size)          # default text sizes\n", "plt.rc('xtick', labelsize=medium_size)    # xtick labels\n", "plt.rc('ytick', labelsize=medium_size)    # ytick labels\n", "plt.rc('legend', fontsize=medium_size)    # legend\n", "plt.rc('axes', titlesize=large_size)      # axes title\n", "plt.rc('axes', labelsize=large_size)      # x and y labels\n", "plt.rc('figure', titlesize=large_size)    # figure title\n"]}, {"cell_type": "markdown", "id": "33743ad1", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_6_1'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L6.1 Introduction to Confidence Intervals</h2>  \n", "\n", "| [Top](#section_6_0) | [Previous Section](#section_6_0) | [Exercises](#exercises_6_1) | [Next Section](#section_6_2) |\n"]}, {"cell_type": "code", "execution_count": null, "id": "929f9553", "metadata": {"tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L6.1-slides\n", "\n", "from IPython.display import IFrame\n", "IFrame(src='https://mitx-8s50.github.io/slides/L06/slides_L06_01.html', width=970, height=550)"]}, {"cell_type": "code", "execution_count": null, "id": "dad5f01c", "metadata": {"tags": ["learner", "py", "lect_01", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L6.1-runcell01\n", "\n", "#probability for events within 1 sigma\n", "pM1=stats.norm.cdf(-1)\n", "p1=stats.norm.cdf(1)\n", "print(\"probability for events within 1 sigma: \", p1-pM1)\n", "print()\n", "\n", "#probability for events strictly < 1 sigma upper bound\n", "pM1=stats.norm.cdf(-1)\n", "p1=stats.norm.cdf(1)\n", "print(\"probability for events strictly < 1 sigma upper bound: \", p1)\n", "print()\n", "\n", "#probability for events within 2 sigma\n", "pM2=stats.norm.cdf(-2)\n", "p2=stats.norm.cdf(2)\n", "print(\"probability for events within 2 sigma: \", p2-pM2)\n", "print()\n", "\n", "#probability for events strictly > 2 sigma upper bound\n", "pM2=stats.norm.cdf(-2)\n", "p2=stats.norm.cdf(2)\n", "print(\"probability for events strictly > 2 sigma upper bound: \", 1-p2)\n", "print()"]}, {"cell_type": "markdown", "id": "9f4c8e0d", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='exercises_6_1'></a>     \n", "\n", "| [Top](#section_6_0) | [Restart Section](#section_6_1) | [Next Section](#section_6_2) |\n"]}, {"cell_type": "markdown", "id": "1ed76c79", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-6.1.1</span>\n", "\n", "Using stats.norm.cdf(), calculate the p value corresponding to $x$ being within $\\pm 3\\sigma$ of the mean in a normal distribution. Enter your answer as a number (not a percentage) with precision 1e-4.\n"]}, {"cell_type": "code", "execution_count": null, "id": "0ca14c6f", "metadata": {"tags": ["draft", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L6.1.1\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "#YOUR CODE HERE\n"]}, {"cell_type": "markdown", "id": "ba0227af", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": [">#### Follow-up 6.1.1a (ungraded)\n", ">\n", ">What is the delta log likelihood that corresponds to a 3 sigma deviation?"]}, {"cell_type": "markdown", "id": "c4b129fb", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-6.1.2</span>\n", "\n", "When computing p-values, we often refer to the region of the distribution that we are working with as \"left-handed\" or \"right-handed\". For instance, if we wanted to know the probability of a left-handed $3\\sigma$ deviation, this would be the area under the curve (the CDF) to the left of the lower $3\\sigma$ bound.\n", "\n", "What is the probability for a right-handed 5$\\sigma$ deviation? What is the probability of ANY deviation greater than 5$\\sigma$?\n", "\n", "Enter your answer as a list of two numbers (not a percentage) times 1e-7, with precision 1e-3. For instance, an answer of `6.238572e-7` would be reported as `6.238`.\n", "    \n", "Your list should be `[p_right_handed_5sigma, p_any_5sigma]`."]}, {"cell_type": "code", "execution_count": null, "id": "b990de3d", "metadata": {"tags": ["draft", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L6.1.2\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "#YOUR CODE HERE\n"]}, {"cell_type": "markdown", "id": "c6df8d24", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_6_2'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L6.2 z-Scores and Confidence Intervals for Other Distributions</h2>  \n", "\n", "| [Top](#section_6_0) | [Previous Section](#section_6_1) | [Exercises](#exercises_6_2) | [Next Section](#section_6_3) |\n"]}, {"cell_type": "code", "execution_count": null, "id": "38a831c7", "metadata": {"tags": ["learner", "py", "lect_02", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L6.2-runcell01\n", "\n", "from scipy import stats\n", "\n", "#Let's do some integrals\n", "p50=stats.norm.cdf(0)\n", "p1=stats.norm.cdf(1)\n", "p2=stats.norm.cdf(2)\n", "p3=stats.norm.cdf(3)\n", "p5=stats.norm.cdf(5)\n", "pM1=stats.norm.cdf(-1)\n", "pM2=stats.norm.cdf(-2)\n", "pM3=stats.norm.cdf(-3)\n", "pM5=stats.norm.cdf(-5)\n", "#print(p50,p1,p2,p3,pM1,pM2,pM3)\n", "\n", "#Whats the probability of things fluctuation more that 1\\sigma\n", "print(p1-pM1,\"within 1 standard deviations\")\n", "print(p2-pM2,\"within 2 standard deviations\")\n", "print(p3-pM3,\"within 3 standard deviations\")\n", "print(p5-pM5,\"within 5 standard deviations\")\n", "\n", "#Sometimes we only consider 1-sided p-values\n", "print((1.-p1),\"to fluctuate above 1 standard deviation\")\n", "print((1.-p3),\"to fluctuate above 3 standard deviation\")\n", "print((1.-p5),\"to fluctuate above 5 standard deviation\")"]}, {"cell_type": "code", "execution_count": null, "id": "073f94bf", "metadata": {"tags": ["learner", "py", "lect_02", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L6.2-runcell03\n", "\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "#code from here(\u00a9 Eric Kim): https://aegis4048.github.io/comprehensive_confidence_intervals_for_python_developers\n", "\n", "#Let's plot a chi2 with 9 degrees of freedom (df)\n", "df = 9 \n", "x = np.linspace(-1, 28, 1000)\n", "y = stats.chi2.pdf(x, df, loc=0, scale=1)\n", "\n", "# two-tailed\n", "#Note we will use this function percent point function(ppf), \n", "#which inverts the cdf and gives a z from a probability\n", "two_right_tail = stats.chi2.ppf(1 - 0.025, df) #left value\n", "two_left_tail  = stats.chi2.ppf(1 - 0.975, df) #right value\n", "print(\"two tail values:\",two_right_tail,two_left_tail)\n", "\n", "# one tailed\n", "one_right_tail = stats.chi2.ppf(1 - 0.05, df)\n", "one_left_tail  = stats.chi2.ppf(1 - 0.95, df)\n", "print(\"one tail values:\",one_right_tail,one_left_tail)\n", "\n", "plt.style.use('seaborn-whitegrid')\n", "fig, axes = plt.subplots(1, 3, figsize=(12, 3))\n", "\n", "for ax in axes:\n", "    ax.plot(x, y, c='black')\n", "    ax.grid(False)\n", "    #ax.xaxis.set_major_formatter(plt.NullFormatter())\n", "    #ax.yaxis.set_major_formatter(plt.NullFormatter())\n", "\n", "#now let's fill this from the left\n", "axes[0].fill_between(x, 0, y, where=(np.array(x) > min(x)) & (np.array(x) <= two_left_tail), facecolor='grey')\n", "axes[0].fill_between(x, 0, y, where=(np.array(x) > two_left_tail) & (np.array(x) < two_right_tail), facecolor='lightgrey')\n", "axes[0].fill_between(x, 0, y, where=(np.array(x) > two_right_tail) & (np.array(x) <= max(x)), facecolor='grey')\n", "\n", "axes[1].fill_between(x, 0, y, where=(np.array(x) > min(x)) & (np.array(x) < one_right_tail), facecolor='lightgrey')\n", "axes[1].fill_between(x, 0, y, where=(np.array(x) > one_right_tail) & (np.array(x) <= max(x)), facecolor='grey')\n", "\n", "axes[2].fill_between(x, 0, y, where=(np.array(x) > min(x)) & (np.array(x) <= one_left_tail), facecolor='grey')\n", "axes[2].fill_between(x, 0, y, where=(np.array(x) > one_left_tail) & (np.array(x) <= max(x)), facecolor='lightgrey')\n", "\n", "fig.tight_layout()"]}, {"cell_type": "code", "execution_count": null, "id": "e2ccf7ae", "metadata": {"tags": ["learner", "py", "lect_02", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L6.2-runcell04\n", "\n", "#Let's compute the mean and RMS of a sample from this distribution\n", "df=9\n", "#Let's sample this distribution\n", "y_chi2 = stats.chi2.rvs(size=1000,df=df)\n", "print(y_chi2[0:5]) #print some valued\n", "print(\"Sampled Mean:\",y_chi2.mean(),\"Sampled Stddev:\",y_chi2.std())\n", "\n", "z=1.5 #Let's deviation corresponding to 1.5sigma in a Gauassian\n", "x = np.linspace(-1, 28, 1000)\n", "y = stats.chi2.pdf(x, df, loc=0, scale=1)\n", "two_right_tail = stats.chi2.ppf(1 - stats.norm.cdf(-z), df)\n", "two_left_tail = stats.chi2.ppf(1 - stats.norm.cdf(z), df)\n", "\n", "def plotItAll(x,y,y_chi2,z):\n", "    #Now let's plot the filled area using the true pdfs and the assumed variations if it were a Gaussian\n", "    plt.style.use('seaborn-whitegrid')\n", "    #plot distribution\n", "    plt.plot(x, y, c='black',label=\"$\\chi^2$\")\n", "    #plot chi2\n", "    plt.hist(y_chi2, histtype='stepfilled', edgecolor='k', alpha=0.4, color='gray', density=True,bins=20,label=\"events\")\n", "    #true values\n", "    plt.fill_between(x, 0, y, where=(np.array(x) > min(x)) & (np.array(x) <= two_left_tail), facecolor='grey')\n", "    plt.fill_between(x, 0, y, where=(np.array(x) > two_right_tail) & (np.array(x) <= max(x)), facecolor='grey')\n", "    #Mean +/- 1 sigma\n", "    plt.axvline(y_chi2.mean(), c='red',label=\"mean\")\n", "    plt.axvline(y_chi2.mean()+y_chi2.std()*z, c='blue',label=\"+/-$\\sigma_{gaus}$\")\n", "    plt.axvline(y_chi2.mean()-y_chi2.std()*z, c='blue')\n", "    plt.xlabel(\"x\")\n", "    plt.ylabel(\"$\\chi^{2}$\")\n", "    plt.legend(loc='upper right')\n", "    plt.show()\n", "plotItAll(x,y,y_chi2,z)"]}, {"cell_type": "markdown", "id": "bf006ac3", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='exercises_6_2'></a>     \n", "\n", "| [Top](#section_6_0) | [Restart Section](#section_6_2) | [Next Section](#section_6_3) |\n"]}, {"cell_type": "markdown", "id": "7d52d14b", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-6.2.1</span>\n", "\n", "In the last section, we were using the language of \"p-values\" and standard deviations. Now we will talk about things in terms of \"confidence\" and \"z-score\". \n", "\n", "What is the confidence level corresponding to a z-score of 4, for a normal distribution? Enter your answer as a number with precision 1e-6."]}, {"cell_type": "code", "execution_count": null, "id": "89c2d385", "metadata": {"tags": ["draft", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L6.2.1\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "pass\n"]}, {"cell_type": "markdown", "id": "e6ed91c8", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-6.2.2</span>\n", "\n", "Again, consider a normal distribution. What is the z-score for an event to be less than some value $x$, where we know the probability that the value is $>x$ is $p=0.40$?\n", "\n", "Enter your answer as a number with precision 1e-3."]}, {"cell_type": "code", "execution_count": null, "id": "1344050b", "metadata": {"tags": ["draft", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L6.2.2\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "pass\n"]}, {"cell_type": "markdown", "id": "e8f22232", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_6_3'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L6.3 Another Example and Rules of Significance</h2>  \n", "\n", "| [Top](#section_6_0) | [Previous Section](#section_6_2) | [Exercises](#exercises_6_3) | [Next Section](#section_6_4) |\n"]}, {"cell_type": "code", "execution_count": null, "id": "d17712ea", "metadata": {"tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L6.3-slides\n", "\n", "from IPython.display import IFrame\n", "IFrame(src='https://mitx-8s50.github.io/slides/L06/slides_L06_03.html', width=970, height=550)"]}, {"cell_type": "code", "execution_count": null, "id": "92d1d411", "metadata": {"tags": ["learner", "py", "lect_03", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L6.3-runcell01\n", "\n", "#NOTE: below we define a random seed for identical results between runs.\n", "#These results may appear slightly different from the related video.\n", "\n", "\n", "#Generate Cauchy data\n", "np.random.seed(6)\n", "y_cauchy = stats.cauchy.rvs(size=10000)\n", "\n", "\n", "#choose z-score\n", "z=1.0\n", "two_right_tail = stats.cauchy.ppf(1 - stats.norm.cdf(-z))\n", "two_left_tail = stats.cauchy.ppf(1 - stats.norm.cdf(z))\n", "print('left/right-handed values corresponding to z-score:', two_left_tail,two_right_tail)\n", "\n", "\n", "#print the mean and stdev of the distribution\n", "fig, ax = plt.subplots(figsize=(12, 6))\n", "y_cauchy = stats.cauchy.rvs(size=10000)\n", "print('[mean of cauchy data, stdev of cauchy data]:', y_cauchy.mean(),z*y_cauchy.std())\n", "\n", "\n", "#plot distribution\n", "ymin = -300\n", "ymax = 300\n", "plt.xlim([ymin,ymax])\n", "x = np.linspace(ymin, ymax, 10000)\n", "y = stats.cauchy.pdf(x, loc=0, scale=1)\n", "plt.plot(x, y, '--', c='black',label=\"f\")\n", "plt.hist(y_cauchy, histtype='stepfilled', edgecolor='k', alpha=0.4, color='gray', density=True,bins=10000)\n", "\n", "\n", "#plot true-sigma\n", "#plt.fill_between(x, 0, y, where=(np.array(x) > min(x)) & (np.array(x) <= two_left_tail), facecolor='grey',label='+/- true $\\sigma$')\n", "#plt.fill_between(x, 0, y, where=(np.array(x) > two_right_tail) & (np.array(x) <= max(x)), facecolor='grey')\n", "plt.fill_between(x, 0, y, where=(np.array(x) < two_right_tail) & (np.array(x) >= two_left_tail), facecolor='grey',label='+/- true $\\sigma$')\n", "\n", "\n", "plt.axvline(y_cauchy.mean(), c='red',label=\"mean\")\n", "plt.axvline(y_cauchy.mean()+y_cauchy.std()*z, c='blue',label='+/- gaus $\\sigma$')\n", "plt.axvline(y_cauchy.mean()-y_cauchy.std()*z, c='blue')\n", "plt.xlabel(\"x\")\n", "plt.ylabel(\"f(x)\")\n", "plt.legend(loc='upper right')\n", "plt.yscale('log')\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "id": "ab7f81a1", "metadata": {"tags": ["learner", "py", "lect_03", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L6.3-runcell02\n", "\n", "#calculate p_value from data\n", "def get_p_value_data(idist, two_left_tail, two_right_tail):\n", "  within_range = []\n", "  for ielem in idist:\n", "    if ielem <= two_right_tail and ielem >= two_left_tail:\n", "      within_range.append(ielem)\n", "  return len(within_range)/len(idist)\n", "\n", "\n", "#Generate Cauchy data\n", "np.random.seed(6)\n", "y_cauchy = stats.cauchy.rvs(size=10000)\n", "\n", "#choose z-score\n", "z=1.0\n", "two_right_tail = stats.cauchy.ppf(1 - stats.norm.cdf(-z))\n", "two_left_tail = stats.cauchy.ppf(1 - stats.norm.cdf(z))\n", "\n", "cauchy_p_value = get_p_value_data(y_cauchy, two_left_tail, two_right_tail)\n", "print(\"p-value from left/right values and data:\", cauchy_p_value)\n", "print()"]}, {"cell_type": "markdown", "id": "ca9fc613", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='exercises_6_3'></a>     \n", "\n", "| [Top](#section_6_0) | [Restart Section](#section_6_3) | [Next Section](#section_6_4) |\n"]}, {"cell_type": "markdown", "id": "80b35f84", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-6.3.1</span>\n", "\n", "What is the probability than an event drawn from a Cauchy distribution falls within 1-sigma of the mean? Use the data that we generated above to calculate your probability, and consider using the function `get_p_value_data()` (or write your own).\n", "\n", "Enter your answer as a number with precision 1e-3."]}, {"cell_type": "code", "execution_count": null, "id": "205d04e6", "metadata": {"tags": ["draft", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L6.3.1\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "#calculate p_value from data\n", "def get_p_value_data(idist, two_left_tail, two_right_tail):\n", "  within_range = []\n", "  for ielem in idist:\n", "    if ielem <= two_right_tail and ielem >= two_left_tail:\n", "      within_range.append(ielem)\n", "  return len(within_range)/len(idist)\n", "\n", "#Generate Cauchy data\n", "np.random.seed(6)\n", "y_cauchy = stats.cauchy.rvs(size=10000)\n", "\n", "#choose z-score\n", "z=1.0\n", "two_right_tail = #YOUR CODE HERE\n", "two_left_tail = #YOUR CODE HERE\n", "\n", "cauchy_p_value = get_p_value_data(y_cauchy, two_left_tail, two_right_tail)\n", "print(\"p-value from left/right values and data:\", cauchy_p_value)\n", "print()\n"]}, {"cell_type": "markdown", "id": "bcd59bbd", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-6.3.2</span>\n", "\n", "What is the p-value that corresponds to a z-score of 1 for a Cauchy distribution? Enter your answer as a number with precision 1e-3."]}, {"cell_type": "code", "execution_count": null, "id": "c15c778b", "metadata": {"tags": ["draft", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L6.3.2\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "pass\n"]}, {"cell_type": "markdown", "id": "ddca039b", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-6.3.3</span>\n", "\n", "Which of the following options best describes a 3$\\sigma$ detection:\n", "\n", "- background noise\n", "- evidence\n", "- discovery\n"]}, {"cell_type": "markdown", "id": "6b8f1fbf", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-6.3.4</span>\n", "\n", "Which of the following options best describes a 5$\\sigma$ detection:\n", "\n", "- background noise\n", "- evidence\n", "- discovery\n"]}, {"cell_type": "markdown", "id": "65acc2bc", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_6_4'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L6.4 Moments of Distributions and Mapping</h2>  \n", "\n", "| [Top](#section_6_0) | [Previous Section](#section_6_3) | [Exercises](#exercises_6_4) | [Next Section](#section_6_5) |\n"]}, {"cell_type": "code", "execution_count": null, "id": "8645cd45", "metadata": {"tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L6.4-slides\n", "\n", "from IPython.display import IFrame\n", "IFrame(src='https://mitx-8s50.github.io/slides/L06/slides_L06_04.html', width=970, height=550)"]}, {"cell_type": "code", "execution_count": null, "id": "102ad113", "metadata": {"tags": ["learner", "py", "lect_04", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L6.4-runcell01\n", "\n", "def raw_moment(X, k, c=0):\n", "    return ((X - c)**k).mean()\n", "\n", "def central_moment(X, k):\n", "    if k == 1:\n", "        return X.mean()\n", "    return raw_moment(X=X, k=k, c=X.mean())\n", "\n", "def print_moments(X,label):\n", "    print(label+\" mean:\",central_moment(X,1))\n", "    print(label+\" var:\" ,central_moment(X,2))\n", "    print(label+\" skew:\",central_moment(X,3))\n", "    print(label+\" kurtosis:\",central_moment(X,4))\n", "\n", "N=1000000\n", "y_norm = stats.norm.rvs(size=N)\n", "print_moments(y_norm,\"normal\")\n", "\n", "df=9\n", "y_chi2 = stats.chi2.rvs(size=N,df=df)\n", "print_moments(y_chi2,\"chi2 df \"+str(df))\n", "\n", "y_cauchy = stats.cauchy.rvs(size=N)\n", "print_moments(y_cauchy,\"cauchy\")\n"]}, {"cell_type": "code", "execution_count": null, "id": "f4299604", "metadata": {"tags": ["learner", "py", "lect_04", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L6.4-runcell02\n", "\n", "x = stats.lognorm.rvs(s=1, loc=0, scale=5, size=1000, random_state=4)\n", "\n", "# plot\n", "def plotdistandq(x,xaxis,evals):\n", "    fig, axes = plt.subplots(1, 2, figsize=(10, 3))\n", "    axes[0].hist(x,density=True)\n", "    axes[0].plot(xaxis,evals)\n", "    stats.probplot(x, dist=stats.norm, plot=axes[1])\n", "    fig.tight_layout()\n", "\n", "xaxis=np.linspace(0,80, 1000)\n", "evals=stats.lognorm.pdf(xaxis,s=1, loc=0, scale=5)\n", "plotdistandq(x,xaxis,evals)\n", "# box-cox transform\n", "xt, lmbda = stats.boxcox(x)\n", "\n", "#now plot gaussian\n", "gxaxis = np.linspace(-2, 5, 1000)\n", "gevals = stats.norm.pdf(gxaxis,xt.mean(),1) \n", "plotdistandq(xt,gxaxis,gevals)\n", "\n", "stats.probplot(xt, dist=stats.norm, plot=axes[1])\n", "fig.tight_layout()"]}, {"cell_type": "code", "execution_count": null, "id": "8c4b38a8", "metadata": {"tags": ["learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L6.4-runcell03\n", "\n", "x = np.abs(stats.cauchy.rvs(size=10000))\n", "\n", "xaxis=np.linspace(0,80, 1000)\n", "evals=np.abs(stats.cauchy.pdf(xaxis))\n", "plotdistandq(x,xaxis,evals)\n", "# box-cox transform\n", "xt, lmbda = stats.boxcox(x)\n", "\n", "#now plot gaussian\n", "gxaxis = np.linspace(-2, 5, 1000)\n", "gevals = stats.norm.pdf(gxaxis,xt.mean(),1) \n", "plotdistandq(xt,gxaxis,gevals)\n", "\n", "stats.probplot(xt, dist=stats.norm, plot=axes[1])\n", "fig.tight_layout()\n", "\n", "print(\"mean:\",xt.mean())\n", "           "]}, {"cell_type": "markdown", "id": "6275dbd8", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='exercises_6_4'></a>     \n", "\n", "| [Top](#section_6_0) | [Restart Section](#section_6_4) | [Next Section](#section_6_5) |\n"]}, {"cell_type": "markdown", "id": "31bab432", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-6.4.1</span>\n", "\n", "Take a $\\chi^2$ distriubtion with 1 degree of freedom, which is very asymmetric, and map it onto a Gaussian. What is the mean of this distribution?\n", "\n", "Complete the code below, which uses a random seed to ensure your answer will match ours. Enter your answer as a number with precision 1e-3.\n"]}, {"cell_type": "code", "execution_count": null, "id": "77a546b4", "metadata": {"tags": ["draft", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L6.4.1\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "np.random.seed(10)\n", "x = stats.chi2.rvs(size=10000,df=1)\n", "\n", "#YOUR CODE HERE"]}, {"cell_type": "markdown", "id": "bfebe511", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_6_5'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L6.5 Monte Carlo Integration</h2>  \n", "\n", "| [Top](#section_6_0) | [Previous Section](#section_6_4) | [Exercises](#exercises_6_5) | [Next Section](#section_6_6) |\n"]}, {"cell_type": "code", "execution_count": null, "id": "dde400ef", "metadata": {"tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L6.5-slides\n", "\n", "from IPython.display import IFrame\n", "IFrame(src='https://mitx-8s50.github.io/slides/L06/slides_L06_05.html', width=970, height=550)"]}, {"cell_type": "code", "execution_count": null, "id": "8fb01aa0", "metadata": {"tags": ["learner", "py", "lect_05", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L6.5-runcell01\n", "\n", "import math\n", "\n", "#First let's just compute the area of a quarter circle with radius 1\n", "def quarterarea(iN):\n", "    area=0\n", "    lXin = np.array([])\n", "    lYin = np.array([])\n", "    lXout = np.array([])\n", "    lYout = np.array([])\n", "    for i0 in range(iN):\n", "        #Sample X and Y\n", "        pX = np.random.uniform(0,1)\n", "        pY = np.random.uniform(0,1)\n", "        #Check if its radius is in 1\n", "        if math.sqrt(pX**2+pY**2) < 1:\n", "            lXin = np.append(lXin,pX)\n", "            lYin = np.append(lYin,pY)\n", "            area += 1 # count it\n", "        else:\n", "            lXout = np.append(lXout,pX)\n", "            lYout = np.append(lYout,pY)\n", "    return (float(area)/float(iN)),lXin,lYin,lXout,lYout\n", "\n", "#sample points\n", "lN=1000\n", "#lN=100000\n", "a,lXin,lYin,lXout,lYout=quarterarea(lN)\n", "print(\"Pi (4*area):\",a*4,\"+/-\",4*a/math.sqrt(lN)) #gotta put an uncertainty\n", "plt.plot(lXin,lYin,marker='.',linestyle = 'None')\n", "plt.plot(lXout,lYout,marker='.',linestyle = 'None')\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "id": "5955f973", "metadata": {"tags": ["learner", "py", "lect_05", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L6.5-runcell02\n", "\n", "from scipy import optimize as opt \n", "\n", "#use this random seed\n", "np.random.seed(10)\n", "\n", "#Now let's consider integrating some random function\n", "def f(x):\n", "    return x**4 + 3*(x-2)**3 - 15*(x)**2 + 1\n", "\n", "#Now let's multiply it by -1 to make the range calculation fast\n", "def fneg(x):\n", "    return -1*(x**4 + 3*(x-2)**3 - 15*(x)**2 + 1)\n", "\n", "#First thing is to define a range in x\n", "xmin=-6\n", "xmax=3\n", "x = np.linspace(xmin, xmax, 100)\n", "#plt.plot(x, f(x));\n", "\n", "#Now we need to find a range in y\n", "sol=opt.minimize_scalar(f,bounds=(xmin, xmax), method='Brent')\n", "ymin=sol.fun\n", "#y-max is to get the minimum of negative f\n", "sol=opt.minimize_scalar(fneg,bounds=(xmin, xmax), method='Brent')\n", "ymax=-1*sol.fun\n", "print('[ymin,ymax]:', ymin, ymax)\n", "\n", "lN=100000\n", "#now, let's sample a 2D grid y-min and y-max and compute the integral\n", "lXin = np.array([])\n", "lYin = np.array([])\n", "lXout = np.array([])\n", "lYout = np.array([])\n", "for i0 in range(lN):\n", "    #Try a uniform distribution\n", "    pX = abs(xmax-xmin)*np.random.uniform(0,1)+xmin\n", "    pY = abs(ymax-ymin)*np.random.uniform(0,1)+ymin\n", "    #Try a normal distribution\n", "    #pX = abs(xmax-xmin)*np.random.normal(0,1)+xmin\n", "    #pY = abs(ymax-ymin)*np.random.normal(0,1)+ymin\n", "    pYMin = f(pX)\n", "    if pY < pYMin:\n", "        lXin = np.append(lXin,pX)\n", "        lYin = np.append(lYin,pY)\n", "    else:\n", "        lXout = np.append(lXout,pX)\n", "        lYout = np.append(lYout,pY)\n", "\n", "\n", "plt.plot(lXin,lYin,marker='.',linestyle = 'None', color='orange')\n", "plt.plot(lXout,lYout,marker='.',linestyle = 'None', color='green')\n", "plt.axvline(sol.x, c='red', lw=3)\n", "plt.plot(x, f(x), 'b-', lw=3)\n", "#plt.ylim(-800,0)\n", "#plt.xlim(-6,3)\n", "plt.show();"]}, {"cell_type": "code", "execution_count": null, "id": "f9fa5537", "metadata": {"tags": ["learner", "py", "lect_05", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L6.5-runcell03\n", "\n", "_,bins,_=plt.hist(lXin,bins=10,alpha=0.5,density=True, label='below')\n", "plt.hist(lXout,alpha=0.5,bins=bins,density=True, label='above')\n", "#plt.xlim(-6,3)\n", "plt.legend(loc=1)\n", "plt.show();\n", "\n", "print(\"number below:\",len(lXin),\"number above:\",len(lXout))\n", "#Note, these numbers will be slightly different for each run\n", "#due to random generation of data"]}, {"cell_type": "markdown", "id": "e1e2edda", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='exercises_6_5'></a>     \n", "\n", "| [Top](#section_6_0) | [Restart Section](#section_6_5) | [Next Section](#section_6_6) |\n"]}, {"cell_type": "markdown", "id": "5e0fcb32", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-6.5.1</span>\n", "\n", "Compute the fraction of events above the line corresponding to the function that we defined previously:\n", "\n", "<pre>\n", "def f(x):\n", "    return x**4 + 3*(x-2)**3 - 15*(x)**2 + 1\n", "</pre>\n", "\n", "Specifically, sample `100000` points from a uniform distribution over the x and y ranges specficed above (ie $-6 < x < 3$ and $f(-6) < y < f(3)$ to compute this fraction.\n", "\n", "Enter your answer as a number with precision 1e-3.\n", "\n", "Hint: Use the `lXout` value from `L6.5-runcell02`. This means the solution is only 3 lines."]}, {"cell_type": "code", "execution_count": null, "id": "e13b4040", "metadata": {"tags": ["draft", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L6.5.1\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "#YOUR CODE HERE\n", "#Note, if you are computing the distributions again, use the following random seed\n", "np.random.seed(10)\n", "pass\n"]}, {"cell_type": "markdown", "id": "93c77464", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-6.5.2</span>\n", "\n", "How would you compute the integral of this function over the range `[-6,3]`? Select the correct answer below:\n", "\n", "- The integral is equal to the number of points above the line defined by our function.\n", "- The integral is equal to the number of points between zero and the line defined by our function.\n", "- The integral is equal to the fraction of points that we calculated, times the area of the region that we defined.\n", "- The integral is equal to the fraction of points between zero and our function, times the area of the region where the simulation is carried out, which must use `0` as an upper bound.\n"]}, {"cell_type": "markdown", "id": "17035d2c", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": [">#### Follow-up 6.5.2a (ungraded)\n", ">\n", ">Calculate the integral numerically. Remember to correctly apply a negative sign, if applicable.\n", ">\n", ">How does your numerically calculated value compare to the expected value? You can explicitly solve the integral mathematically, or use a built-in `scipy` integration method to compare to your Monte Carlo integration."]}, {"cell_type": "code", "execution_count": null, "id": "6ea6ab33", "metadata": {"tags": ["draft", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>FOLLOW-UP: L6.5.2a\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "#YOUR CODE HERE\n", "pass\n"]}, {"cell_type": "markdown", "id": "03d5d7fa", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_6_6'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L6.6 Returning to Fitting Supernova Data</h2>  \n", "\n", "| [Top](#section_6_0) | [Previous Section](#section_6_5) | [Exercises](#exercises_6_6) | [Next Section](#section_6_7) |\n"]}, {"cell_type": "code", "execution_count": null, "id": "b2ce6935", "metadata": {"tags": ["learner", "py", "lect_06", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L6.6-runcell01\n", "import math\n", "import numpy as np\n", "import csv\n", "import matplotlib.pyplot as plt\n", "from scipy import stats\n", "\n", "#Let's try to understand how good the fits we made in last Lesson are, let's load the supernova data again\n", "label='data/L04/sn_z_mu_dmu_plow_union2.1.txt'\n", "\n", "def distanceconv(iMu):\n", "    power=iMu/5+1\n", "    return 10**power\n", "\n", "def distanceconverr(iMu,iMuErr):\n", "    power=iMu/5+1\n", "    const=math.log(10)/5.\n", "    return const*(10**power)*iMuErr\n", "\n", "def load(iLabel,iMaxZ=0.1):\n", "    redshift=np.array([])\n", "    distance=np.array([])\n", "    distance_err=np.array([])\n", "    with open(iLabel,'r') as csvfile:\n", "        plots = csv.reader(csvfile, delimiter='\\t')\n", "        for row in plots:\n", "            if float(row[1]) > iMaxZ:\n", "                continue\n", "            redshift = np.append(redshift,float(row[1]))\n", "            distance = np.append(distance,distanceconv(float(row[2])))\n", "            distance_err = np.append(distance_err,distanceconverr(float(row[2]),float(row[3])))\n", "    return redshift,distance,distance_err  \n", "        \n", "#Now let's run the regression again\n", "def variance(isamples):\n", "    mean=isamples.mean()\n", "    n=len(isamples)\n", "    tot=0\n", "    for pVal in isamples:\n", "        tot+=(pVal-mean)**2\n", "    return tot/n\n", "\n", "def covariance(ixs,iys):\n", "    meanx=ixs.mean()\n", "    meany=iys.mean()\n", "    n=len(ixs)\n", "    tot=0\n", "    for i0 in range(len(ixs)):\n", "        tot+=(ixs[i0]-meanx)*(iys[i0]-meany)\n", "    return tot/n\n", "\n", "def linear(ix,ia,ib):\n", "    return ia*ix+ib\n", "\n", "redshift,distance,distance_err=load(label)\n", "var=variance(redshift)\n", "cov=covariance(redshift,distance)\n", "A=cov/var\n", "const=distance.mean()-A*redshift.mean()\n", "xvals = np.linspace(0,0.1,100)\n", "yvals = []\n", "for pX in xvals:\n", "    yvals.append(linear(pX,A,const))\n", "\n", "plt.plot(xvals,yvals)\n", "plt.errorbar(redshift,distance,yerr=distance_err,marker='.',linestyle = 'None', color = 'black')\n", "plt.xlabel(\"z(redshift)\")\n", "plt.ylabel(\"distance(pc)\")\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "id": "ebede43b", "metadata": {"tags": ["learner", "py", "lect_06", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L6.6-runcell02\n", "\n", "def residualsComp(redshift,distance,distance_err):\n", "    #Compute residuals\n", "    residuals=np.array([])\n", "    for i0 in range(len(redshift)):\n", "        pResid=linear(redshift[i0],A,const)-distance[i0]\n", "        residuals = np.append(residuals,pResid/distance_err[i0])\n", "    \n", "    #Make a histogram\n", "    y0, bin_edges = np.histogram(residuals, bins=30)\n", "    bin_centers = 0.5*(bin_edges[1:] + bin_edges[:-1])\n", "    norm0=len(residuals)*(bin_edges[-1]-bin_edges[0])/30.\n", "    plt.errorbar(bin_centers,y0/norm0,yerr=y0**0.5/norm0,marker='.',drawstyle = 'steps-mid')\n", "    \n", "    #Plot a Gaussian\n", "    k=np.arange(bin_edges[0],bin_edges[-1],0.05)\n", "    normal=stats.norm.pdf(k,0,1)\n", "    #First let's look at the moments \n", "    normalpoints=stats.norm.rvs(0,1,1000)\n", "    print_moments(residuals,\"residuals\")\n", "    print_moments(normalpoints,\"normal distribution\")\n", "\n", "    #Now let's plot it\n", "    plt.plot(k,normal,'o-')\n", "    plt.xlabel(\"number of successes\")\n", "    plt.ylabel(\"probability\")\n", "    plt.show()\n", "    return residuals\n", "\n", "residuals=residualsComp(redshift,distance,distance_err)"]}, {"cell_type": "code", "execution_count": null, "id": "e032b337", "metadata": {"tags": ["learner", "py", "lect_06", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L6.6-runcell03\n", "\n", "#now let's look at the chi2\n", "chi2=np.sum(residuals**2)\n", "\n", "print(\"Total chi2:\",chi2,\"NDOF\",len(residuals)-2)\n", "print(\"Normalized chi2:\",chi2/(len(residuals)-2))\n", "print(\"Probability of chi2:\",1-stats.chi2.cdf(chi2,(len(residuals)-2)))\n", "print()\n", "\n", "#Let's plot it for good measure too\n", "x = np.linspace(0,len(residuals)*2)\n", "chi2d=stats.chi2.pdf(x,len(residuals-2)) # 40 bins\n", "plt.plot(x,chi2d,label='chi2')\n", "plt.axvline(chi2, c='red')\n", "plt.legend(loc='lower right')\n", "\n", "ndof=(len(residuals)-2)\n", "chi2ppf0=stats.chi2.ppf(0.5,ndof)\n", "chi2ppf1=stats.chi2.ppf(0.15,ndof)\n", "chi2ppf2=stats.chi2.ppf(0.85,ndof)\n", "#chi2ppf1=stats.chi2.ppf(0.025,ndof)\n", "#chi2ppf2=stats.chi2.ppf(1-0.025,ndof)\n", "print(\"Central Vvalue\",chi2ppf0)\n", "print(\"Sigma Low\",chi2ppf1-chi2ppf0)\n", "print(\"Sigma High\",chi2ppf2-chi2ppf0)\n", "\n", "plt.axvline(chi2ppf1, c='blue')\n", "plt.axvline(chi2ppf2, c='blue')\n", "plt.show()"]}, {"cell_type": "markdown", "id": "f208eee9", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='exercises_6_6'></a>     \n", "\n", "| [Top](#section_6_0) | [Restart Section](#section_6_6) | [Next Section](#section_6_7) |\n"]}, {"cell_type": "markdown", "id": "c87f8921", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-6.6.1</span>\n", "\n", "Fill in the blank: Anything above ___ for chi squared probability is a sign of a good fit. Enter your answer as a number with precision 1e-3."]}, {"cell_type": "markdown", "id": "cc95fbdd", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-6.6.2</span>\n", "\n", "Fill in the blank: For a normal distribution, a good fit has a normalized chi squared value near ___. Enter your answer as a number with precision 1e-3."]}, {"cell_type": "markdown", "id": "5cfc7106", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-6.6.3</span>\n", "\n", "Ok, now let's repeat the linear fit above without a cut on the redshift. Let's run our full slew of metrics on it like we did before. Complete the code below and analyze the output.\n", "\n", "What is the value of the normalized (or reduced) chi-square metric? Is this a good fit or a bad fit? Enter your answer as a number with precision 1e-2."]}, {"cell_type": "code", "execution_count": null, "id": "06dba6c3", "metadata": {"tags": ["py", "learner_chopped", "draft"]}, "outputs": [], "source": ["#>>>RUN: L6.6.3\n", "\n", "#run regression\n", "redshift,distance,distance_err=load(label,10000)\n", "var=variance(redshift)\n", "cov=covariance(redshift,distance)\n", "A=cov/var\n", "const=distance.mean()-A*redshift.mean()\n", "xvals = np.linspace(0,1.4,100)\n", "yvals = []\n", "for pX in xvals:\n", "    yvals.append(linear(pX,A,const))\n", "\n", "#plot it\n", "plt.plot(xvals,yvals)\n", "plt.errorbar(redshift,distance,yerr=distance_err,marker='.',linestyle = 'None', color = 'black')\n", "plt.xlabel(\"z(redshift)\")\n", "plt.ylabel(\"distance(pc)\")\n", "plt.show()\n", "\n", "residuals=residualsComp(redshift,distance,distance_err)\n", "#now let's look at the chi2\n", "#YOUR CODE HERE"]}, {"cell_type": "markdown", "id": "77bf65ae", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_6_7'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L6.7 Fitting with a More Accurate Model</h2>  \n", "\n", "| [Top](#section_6_0) | [Previous Section](#section_6_6) | [Exercises](#exercises_6_7) | [Next Section](#section_6_8) |\n"]}, {"cell_type": "code", "execution_count": null, "id": "64de7f26", "metadata": {"tags": ["learner", "py", "lect_07", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L6.7-runcell02\n", "\n", "#We are not going to plot the fit first, let's just use our barrage of statistics to check if its ok\n", "def hubble(z,Om):\n", "    pVal=Om*(1+z)**3+(1.-Om)\n", "    return np.sqrt(pVal)\n", "\n", "def lumidistance(z,h0,Om):\n", "    integral=0\n", "    nint=100\n", "    for i0 in range(nint):\n", "        zp=z*float(i0)/100.\n", "        dz=z/float(nint)\n", "        pVal=1./(1e-5+hubble(zp,Om))\n", "        integral += pVal*dz\n", "    d=(1.+z)*integral*(1e6*3e5/h0)\n", "    return d\n", "\n", "print(\"test Lumi\",lumidistance(1,70,0.3))\n"]}, {"cell_type": "markdown", "id": "366c9fb5", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-6.7.1</span>\n", "\n", "How would more dark energy change the luminosity distance over redshift? You can approach this problem mathematically, or simply change the apppropriate parameter in the function `lumidistance()` to compute the luminosity distance at different values.\n", "\n", "Based on your observations, if there is more dark energy, the luminosity distance should:\n", "\n", "- get larger\n", "- get smaller\n", "- stay the same\n"]}, {"cell_type": "code", "execution_count": null, "id": "98588ef5", "metadata": {"tags": ["draft", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L6.7.1\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "pass"]}, {"cell_type": "markdown", "id": "7741827a", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_6_8'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L6.8 Fit to Full Cosmological Model</h2>     \n", "\n", "| [Top](#section_6_0) | [Previous Section](#section_6_7) | [Exercises](#exercises_6_8) |\n"]}, {"cell_type": "code", "execution_count": null, "id": "aec03b27", "metadata": {"tags": ["learner", "py", "lect_08", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L6.8-runcell01\n", "\n", "import lmfit\n", "\n", "model  = lmfit.Model(lumidistance)\n", "p = model.make_params(h0=70,Om=0.2)\n", "result = model.fit(data=distance, params=p, z=redshift, weights=1./distance_err)\n", "lmfit.report_fit(result)\n", "plt.figure()\n", "result.plot()"]}, {"cell_type": "code", "execution_count": null, "id": "eb1f572a", "metadata": {"tags": ["learner", "py", "lect_08", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L6.8-runcell02\n", "from scipy import optimize as opt \n", "\n", "def loglike(x):\n", "    lTot=0\n", "    for i0 in range(len(redshift)):\n", "        xtest=lumidistance(redshift[i0],x[0],x[1])\n", "        #lTot = lTot+(distance[i0]-xtest)**2\n", "        lTot = lTot+((1./distance_err[i0])**2)*(distance[i0]-xtest)**2\n", "    return lTot #*0.5 The above is 2 times loglike\n", "\n", "def residuals(x):\n", "    residuals=np.array([])\n", "    for i0 in range(len(redshift)):\n", "        pResid=lumidistance(redshift[i0],sol.x[0],sol.x[1])-distance[i0]\n", "        residuals = np.append(residuals,pResid/distance_err[i0])\n", "    return residuals\n", "\n", "\n", "x0 = np.array([60.,0.2])\n", "ps = [x0]\n", "bnds = ((0, 1000), (0, 1.0))\n", "sol=opt.minimize(loglike, x0,bounds=bnds, tol=1e-6)\n", "print(sol)\n", "residuals=residuals(sol.x)\n", "print_moments(residuals,\"residuals\")\n", "chi2=np.sum(residuals**2)\n", "print(\"Total chi2:\",chi2,\"NDOF\",len(residuals)-2)\n", "print(\"Normalized chi2:\",chi2/(len(residuals)-2))\n", "print(\"Probability of chi2:\",1-stats.chi2.cdf(chi2,(len(residuals)-2)))\n", "\n", "#Let's plot it for good measure too\n", "x = np.linspace(0,len(residuals)*2)\n", "chi2d=stats.chi2.pdf(x,len(residuals-2)) # 40 bins\n", "plt.plot(x,chi2d,label='chi2')\n", "plt.axvline(chi2, c='red')\n", "plt.legend(loc='lower right')\n", "plt.show();"]}, {"cell_type": "code", "execution_count": null, "id": "f856518b", "metadata": {"tags": ["learner", "py", "lect_08", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L6.8-runcell03\n", "\n", "#Plot it against the data\n", "xvals = np.linspace(0,1.4,100)\n", "yvals = []\n", "for pX in xvals:\n", "    yvals.append(lumidistance(pX,sol.x[0],sol.x[1]))\n", "\n", "plt.errorbar(redshift,distance,yerr=distance_err,marker='.',linestyle = 'None', color = 'black')\n", "plt.plot(xvals,yvals)\n", "plt.show()\n", "\n", "#Histogram the residuals\n", "y0, bin_edges = np.histogram(residuals, bins=30)\n", "bin_centers = 0.5*(bin_edges[1:] + bin_edges[:-1])\n", "norm0=len(residuals)*(bin_edges[-1]-bin_edges[0])/30.\n", "plt.errorbar(bin_centers,y0/norm0,yerr=y0**0.5/norm0,marker='.',drawstyle = 'steps-mid')\n", "k=np.arange(bin_edges[0],bin_edges[-1],0.05)\n", "normal=stats.norm.pdf(k,0,1)\n", "plt.plot(k,normal,'o-')\n", "plt.show()\n", "\n", "x = np.linspace(len(residuals)*0.5,len(residuals)*1.5)\n", "chi2d=stats.chi2.pdf(x,len(residuals-2)) # 40 bins\n", "plt.plot(x,chi2d,label='chi2')\n", "plt.axvline(chi2, c='red')\n", "plt.legend(loc='lower right')\n", "plt.show()\n", "\n", "\n"]}, {"cell_type": "markdown", "id": "fff3f8e5", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='exercises_6_8'></a>   \n", "\n", "| [Top](#section_6_0) | [Restart Section](#section_6_8) |\n"]}, {"cell_type": "markdown", "id": "bff37c58", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-6.8.1</span>\n", "\n", "So, given the Friedmann equations, we can add back the curvature term:\n", "\n", "$$ d(z) = ct^{\\prime} = (1+z)ct = (1+z)\\frac{c}{h_{0}}\\int_{0}^{z} \\frac{dz^{\\prime}}{\\sqrt{\\Omega_{M}\\left(1+z^{\\prime}\\right)^{3} + \\Omega_{\\kappa}\\left(1+z^{\\prime}\\right)^{2}+ 1-\\Omega_{M}-\\Omega_{\\kappa}}}$$\n", "\n", "Adjust the `lumidistance()` function to fit for curvature. What is the value of $\\Omega_{\\kappa}$ if we perform a new fit to the data? What do you think this this is implying? \n", "\n", "Enter your answer as a number with precision 1e-2.\n"]}, {"cell_type": "code", "execution_count": null, "id": "6ddb6375", "metadata": {"tags": ["draft", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L6.8.1\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "def hubble_curve(z,Om,OmK):\n", "    return #YOUR CODE HERE\n", "\n", "def lumidistance_curve(z,h0,Om,OmK):\n", "    return #YOUR CODE HERE\n", "\n", "\n", "model  = lmfit.Model(lumidistance_curve)\n", "p = model.make_params(h0=70,Om=0.2,OmK=0.0)\n", "result = model.fit(data=distance, params=p, z=redshift, weights=1./distance_err)\n", "lmfit.report_fit(result)\n", "result.plot();\n"]}], "metadata": {"celltoolbar": "Tags", "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}