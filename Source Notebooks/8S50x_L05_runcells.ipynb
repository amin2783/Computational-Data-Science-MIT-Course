{"cells": [{"cell_type": "markdown", "id": "e452ed9b", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<hr style=\"height: 1px;\">\n", "<i>This notebook was authored by the 8.S50x Course Team, Copyright 2022 MIT All Rights Reserved.</i>\n", "<hr style=\"height: 1px;\">\n", "<br>\n", "\n", "<h1>Lesson 5: Uncertainty</h1>\n"]}, {"cell_type": "markdown", "id": "18aea4b2", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_5_0'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L5.0 Overview</h2>\n"]}, {"cell_type": "markdown", "id": "9f9e2407", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<h3>Navigation</h3>\n", "\n", "<table style=\"width:100%\">\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_5_1\">L5.1 What Do We Call Uncertainty?</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_5_1\">L5.1 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_5_2\">L5.2 Extracting Uncertainty For Linear Fit</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_5_2\">L5.2 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_5_3\">L5.3 Computing Uncertainty</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_5_3\">L5.3 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_5_4\">L5.4 Introduction to Likelihood</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_5_4\">L5.4 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_5_5\">L5.5 An Example: Auger Data (Part 1)</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_5_5\">L5.5 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_5_6\">L5.6 An Example: Auger Data (Part 2)</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_5_6\">L5.6 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_5_7\">L5.7 Log-Likelihood and Chi-square</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_5_7\">L5.7 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_5_8\">L5.8 Minimizing</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_5_8\">L5.8 Exercises</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_5_9\">L5.9 Comparison Using lmfit</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_5_9\">L5.9 Exercises</a></td>\n", "    </tr>\n", "</table>\n", "\n"]}, {"cell_type": "markdown", "id": "192f785f", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<h3>Importing Data (Colab Only)</h3>\n", "\n", "If you are in a Google Colab environment, run the cell below to import the data for this notebook. Otherwise, if you have downloaded the course repository, you do not have to run the cell below.\n", "\n", "See the source and attribution information below:\n", "\n", ">data: data/L05/sn_z_mu_dmu_plow_union2.1.txt <br>\n", ">source: http://supernova.lbl.gov/Union/ <br>\n", ">attribution: The Supernova Cosmology Project, arXiv:1105.3470v1 <br>\n", ">license type: https://arxiv.org/licenses/nonexclusive-distrib/1.0/license.html \n", "\n", ">data: data/L05/events_a4_1space.dat, data/L05/events_a8_1space.dat <br>\n", ">source: https://www.auger.org/index.php/science/data <br>\n", ">source : https://arxiv.org/abs/1709.07321 <br>\n", ">attribution: Pierre Auger Collaboration, arXiv:1709.07321v1 <br>\n", ">license type: https://creativecommons.org/licenses/by-sa/4.0/ "]}, {"cell_type": "code", "execution_count": null, "id": "74d40cfb", "metadata": {"tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L5.0-runcell02\n", "\n", "#importing data from git repository\n", "\n", "!git init\n", "!git remote add -f origin https://github.com/mitx-8s50/nb_LEARNER/\n", "!git config core.sparseCheckout true\n", "!echo 'data/L05' >> .git/info/sparse-checkout\n", "!git pull origin main"]}, {"cell_type": "code", "execution_count": null, "id": "85cfcfb3", "metadata": {"tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L5.0-runcell01\n", "\n", "!pip install lmfit\n", "!pip install astropy"]}, {"cell_type": "code", "execution_count": null, "id": "4bd05771", "metadata": {"tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L5.0-runcell02\n", "\n", "import numpy as np               #https://numpy.org/doc/stable/\n", "import matplotlib.pyplot as plt  #https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.html\n", "import csv                       #https://docs.python.org/3/library/csv.html \n", "import math                      #https://docs.python.org/3/library/math.html\n", "from scipy import stats          #https://docs.scipy.org/doc/scipy/reference/stats.html"]}, {"cell_type": "code", "execution_count": null, "id": "34992da6", "metadata": {"tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L5.0-runcell02\n", "\n", "#set plot resolution\n", "%config InlineBackend.figure_format = 'retina'\n", "\n", "#set default figure parameters\n", "plt.rcParams['figure.figsize'] = (9,6)\n", "\n", "medium_size = 12\n", "large_size = 15\n", "\n", "plt.rc('font', size=medium_size)          # default text sizes\n", "plt.rc('xtick', labelsize=medium_size)    # xtick labels\n", "plt.rc('ytick', labelsize=medium_size)    # ytick labels\n", "plt.rc('legend', fontsize=medium_size)    # legend\n", "plt.rc('axes', titlesize=large_size)      # axes title\n", "plt.rc('axes', labelsize=large_size)      # x and y labels\n", "plt.rc('figure', titlesize=large_size)    # figure title\n"]}, {"cell_type": "markdown", "id": "419c49c2", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_5_1'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L5.1 What Do We Call Uncertainty?</h2>  \n", "\n", "| [Top](#section_5_0) | [Previous Section](#section_5_0) | [Exercises](#exercises_5_1) | [Next Section](#section_5_2) |\n"]}, {"cell_type": "code", "execution_count": null, "id": "2517d1e5", "metadata": {"tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L5.1-slides\n", "\n", "from IPython.display import IFrame\n", "IFrame(src='https://mitx-8s50.github.io/slides/L05/slides_L05_01.html', width=970, height=550)"]}, {"cell_type": "code", "execution_count": null, "id": "747d1d1d", "metadata": {"tags": ["learner", "py", "lect_01", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L5.1-runcell01\n", "\n", "import numpy as np\n", "import csv\n", "import math\n", "\n", "#Let's try to understand how good the fits we made in last Lesson are, let's load the supernova data again\n", "label='data/L05/sn_z_mu_dmu_plow_union2.1.txt'\n", "\n", "\n", "def distanceconv(iMu):\n", "    power=iMu/5+1\n", "    return 10**power\n", "\n", "def distanceconverr(iMu,iMuErr):\n", "    power=iMu/5+1\n", "    const=math.log(10)/5.\n", "    return const*(10**power)*iMuErr\n", "\n", "#Now let's zoom in on the small redshift data\n", "def load(iLabel,iZMax):\n", "    redshift=np.array([])\n", "    distance=np.array([])\n", "    distance_err=np.array([])\n", "    with open(label,'r') as csvfile:\n", "        plots = csv.reader(csvfile, delimiter='\\t')\n", "        for row in plots:\n", "            if float(row[1]) > iZMax:\n", "                continue\n", "            redshift = np.append(redshift,float(row[1]))\n", "            distance = np.append(distance,distanceconv(float(row[2])))\n", "            distance_err = np.append(distance_err,distanceconverr(float(row[2]),float(row[3])))\n", "    return redshift,distance,distance_err\n", "\n", "redshift=np.array([])\n", "distance=np.array([])\n", "distance_err=np.array([])\n", "redshift,distance,distance_err = load(label,0.1)"]}, {"cell_type": "code", "execution_count": null, "id": "8445621a", "metadata": {"tags": ["learner", "py", "lect_01", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L5.1-runcell02\n", "\n", "import matplotlib.pyplot as plt\n", "\n", "\n", "#Now let's run the regression again\n", "def variance(isamples):\n", "    mean=isamples.mean()\n", "    n=len(isamples)\n", "    tot=0\n", "    for pVal in isamples:\n", "        tot+=(pVal-mean)**2\n", "    return tot/n\n", "\n", "def covariance(ixs,iys):\n", "    meanx=ixs.mean()\n", "    meany=iys.mean()\n", "    n=len(ixs)\n", "    tot=0\n", "    for i0 in range(len(ixs)):\n", "        tot+=(ixs[i0]-meanx)*(iys[i0]-meany)\n", "    return tot/n\n", "\n", "def linear(ix,ia,ib):\n", "    return ia*ix+ib\n", "\n", "def regress(redshift,distance):\n", "    #Let's regress\n", "    var=variance(redshift)\n", "    cov=covariance(redshift,distance)\n", "    A=cov/var\n", "    b=distance.mean()-A*redshift.mean()\n", "    #Done!\n", "    return A,b\n", "\n", "def plotAll(redshift,distance,distance_err,A,b):\n", "    #now let's plot it\n", "    xmax=np.max(redshift)\n", "    xvals = np.linspace(0,xmax,100)\n", "    yvals = []\n", "    for pX in xvals:\n", "        yvals.append(linear(pX,A,b))\n", "\n", "    #Plot the line\n", "    plt.plot(xvals,yvals)\n", "    plt.errorbar(redshift,distance,yerr=distance_err,marker='.',linestyle = 'None', color = 'black')\n", "    plt.xlabel('redshift(z)', fontsize=15) #Label x\n", "    plt.ylabel('distances(parsec)', fontsize=15)#Label y\n", "    plt.show()\n", "    #Print it out\n", "    print(\"Hubbles Constant:\",1e6*3e5/A,\"intercept\",b)#Note 1e6 is from pc to Mpc and 3e5 is c in km/s\n", "\n", "A,b=regress(redshift,distance)\n", "plotAll(redshift,distance,distance_err,A,b)"]}, {"cell_type": "code", "execution_count": null, "id": "b20dd4d1", "metadata": {"tags": ["learner", "py", "lect_01", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L5.1-runcell03\n", "\n", "from scipy import stats\n", "\n", "def residual(func,args,redshift,distance,distance_err=[]):\n", "    residuals=np.array([])\n", "    for i0 in range(len(redshift)):\n", "        pResid=func(redshift[i0],args[0],args[1])-distance[i0]\n", "        if len(distance_err) > 0:      \n", "            pResid=pResid/distance_err[i0]\n", "        residuals = np.append(residuals,pResid)\n", "    return residuals\n", "\n", "#This time we are going to look at a histogram of the residuals\n", "def plotHist(residuals):\n", "    y0, bin_edges = np.histogram(residuals, bins=30)\n", "    bin_centers = 0.5*(bin_edges[1:] + bin_edges[:-1])\n", "    norm0=len(residuals)*(bin_edges[-1]-bin_edges[0])/30.\n", "    plt.errorbar(bin_centers,y0/norm0,yerr=y0**0.5/norm0,marker='.',drawstyle = 'steps-mid')\n", "    \n", "    #for good measure, let's compare this to a gaussian distribution\n", "    k=np.linspace(bin_edges[0],bin_edges[-1],100)\n", "    normal=stats.norm.pdf(k,0,residuals.std())\n", "    plt.plot(k,normal,'o-')\n", "    plt.xlabel(\"y$_{residual}$\")\n", "    plt.ylabel(\"probability\")\n", "    plt.show()\n", "    \n", "residuals=residual(linear,[A,b],redshift,distance,distance_err)\n", "plotHist(residuals)"]}, {"cell_type": "markdown", "id": "7dafc331", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='exercises_5_1'></a>     \n", "\n", "| [Top](#section_5_0) | [Restart Section](#section_5_1) | [Next Section](#section_5_2) |\n"]}, {"cell_type": "markdown", "id": "0cbda452", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-5.1.1</span>\n", "\n", "Consider the residual distribution found above, but now divide by the uncertainty of each measurement, that is, following the formula:\n", "\n", "$$\n", "\\begin{equation}\n", "y^{resid}_{i} = \\frac{f(x_{i})-y_{true, i}}{\\sigma_{y,i}}\n", "\\end{equation}\n", "$$\n", "\n", "If we plot this, and it is truly Gaussian, what are the *expected* values of the mean and stdev of the normalized residual distribution? Enter your answer as a list of two numbers with precision 1e-3: `[mean, stdev]`."]}, {"cell_type": "markdown", "id": "1e504b06", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-5.1.2</span>\n", "\n", "Now use the data to compute the mean and standard deviation of the distribution defined by:\n", "\n", "$$\n", "\\begin{equation}\n", "y^{resid}_{i} = \\frac{f(x_{i})-y_{true, i}}{\\sigma_{y,i}}\n", "\\end{equation}\n", "$$\n", "\n", "**Hint: There is an option to do this in the function that we previously defined.**\n", "\n", "How do the actual values compare to the values of an ideal Gaussian? Enter your answers found using the data as a list of two numbers with precision 1e-3: `[mean, stdev]`.\n", "\n", "\n", "You may wish to use the starting code below."]}, {"cell_type": "code", "execution_count": null, "id": "a41ab1af", "metadata": {"tags": ["draft", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L5.1.2\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "residuals=#YOUR CODE HERE\n", "plotHist(residuals)\n", "\n", "print(\"Ideally we should have a Gaussian with mean(residuals)=0 Instead we have\",residuals.mean())\n", "print(\"Ideally we should have a Gaussian with std(residuals)=1. Instead we have\",residuals.std())\n"]}, {"cell_type": "markdown", "id": "13dff32e", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-5.1.3</span>\n", "\n", "Load the supernova data for entries up to a redshift of 0.4. You can do that by completing the line of code below. Now, compute the residuals dividing by the error, as above. What is the mean and RMS of the residuals now? Why are the residuals not a Gaussian shape? \n", "\n", "Enter your answer as a list of two numbers with precision 1e-3: `[mean, stdev]`."]}, {"cell_type": "code", "execution_count": null, "id": "150f8fb4", "metadata": {"tags": ["py", "draft", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L5.1.3\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "redshift02,distance02,distance02_err = load(label,0.4)\n", "\n", "#Find these parameters by running the regression using regress()\n", "A02,b02=#YOUR CODE HERE\n", "\n", "plotAll(redshift02,distance02,distance02_err,A02,b02)\n", "\n", "#plot regression to check\n", "residuals02=#YOUR CODE HERE\n", "plotHist(residuals02)\n", "\n", "print(\"Ideally we should have a Gaussian with mean(residuals)=0 Instead we have\",residuals.mean())\n", "print(\"Ideally we should have a Gaussian with std(residuals)=1. Instead we have\",residuals.std())\n"]}, {"cell_type": "markdown", "id": "88e8c67d", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_5_2'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L5.2 Extracting Uncertainty For Linear Fit</h2>  \n", "\n", "| [Top](#section_5_0) | [Previous Section](#section_5_1) | [Exercises](#exercises_5_2) | [Next Section](#section_5_3) |\n"]}, {"cell_type": "markdown", "id": "05c0d4ae", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='exercises_5_2'></a>     \n", "\n", "| [Top](#section_5_0) | [Restart Section](#section_5_2) | [Next Section](#section_5_3) |\n"]}, {"cell_type": "markdown", "id": "34f294e9", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 5.2.1</span>\n", "\n", "Consider a fourth-order polynomial:\n", "\n", "$$f(x) = a_{4}x^4 + a_{3}x^3 + a_{2}x^2 + a_{1}x + a_{0}$$  \n", "\n", "If we are using this as our fit function for data consisting of `N` points, how many degrees of freedom do we have? Express your answer in terms of `N`."]}, {"cell_type": "markdown", "id": "4b5e040f", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 5.2.2</span>\n", "\n", "For the linear function in the example above, the variance in $A$ was expressed as: $\\rm{Var}(A)=\\frac{1}{N-2}\\frac{\\rm{Var}(y)}{\\rm{Var}(x)}$.\n", "\n", "What is the variance in $b$, expressed in terms of $\\rm{Var}(y)$,  $\\rm{Var}(x)$, $\\bar{x}$, and $N$? Use the appropriate degrees of freedom, and express $\\rm{Var}(y)$ as `Vary`, $\\rm{Var}(x)$ as `Varx`, and $\\bar{x}$ as `xbar`."]}, {"cell_type": "markdown", "id": "5dadce46", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_5_3'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L5.3 Computing Uncertainty</h2>  \n", "\n", "| [Top](#section_5_0) | [Previous Section](#section_5_2) | [Exercises](#exercises_5_3) | [Next Section](#section_5_4) |\n"]}, {"cell_type": "code", "execution_count": null, "id": "48dcdac9", "metadata": {"tags": ["learner", "py", "lect_03", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L5.3-runcell01\n", "\n", "residuals=residual(linear,[A,b],redshift,distance)\n", "VarY=np.sum(residuals**2)/(len(redshift)-2)\n", "VarA=VarY/variance(redshift)/(len(redshift)-2)\n", "Varb=VarA*(redshift.mean())**2+VarY/(len(redshift)-2)\n", "print(\"Hubbles Constant:\",1e6*3e5/A,\"+/-\",1e6*3e5*math.sqrt(VarA)/A/A,\"intercept\",b,\"+/-\",math.sqrt(Varb))#Note 1e6 is from pc to Mpc and 3e5 is c in km/s\n"]}, {"cell_type": "code", "execution_count": null, "id": "21d3a5ed", "metadata": {"tags": ["learner", "py", "lect_03", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L5.3-runcell02\n", "\n", "weights=np.array([])\n", "for pVal in distance_err:\n", "    weights = np.append(weights,1./pVal/pVal)\n", "\n", "#Now let's do it with weights\n", "def variance_w(isamples,iweights):\n", "    mean=np.average(isamples,weights=iweights)\n", "    sumw=np.sum(iweights)\n", "    tot=0\n", "    for i0 in range(len(isamples)):\n", "        tot+=iweights[i0]*(isamples[i0]-mean)**2\n", "    return tot/sumw\n", "\n", "def covariance_w(ixs,iys,iweights):\n", "    meanx=np.average(ixs,weights=iweights)\n", "    meany=np.average(iys,weights=iweights)\n", "    sumw=np.sum(iweights)\n", "    tot=0\n", "    for i0 in range(len(ixs)):\n", "        tot+=iweights[i0]*(ixs[i0]-meanx)*(iys[i0]-meany)\n", "    return tot/sumw\n", "\n", "def regress_w(redshift,weights,distance):\n", "    varw=variance_w(redshift,weights)\n", "    covw=covariance_w(redshift,distance,weights)\n", "    Aw=covw/varw\n", "    bw=np.average(distance,weights=weights)-Aw*np.average(redshift,weights=weights)\n", "    return Aw,bw\n", "\n", "Aw,bw=regress_w(redshift,weights,distance)\n", "plotAll(redshift,distance,distance_err,Aw,bw)\n", "\n", "def resid_w(func,args,distance,weights):\n", "    residualsw=np.array([])\n", "    for i0 in range(len(redshift)):\n", "        pResid=linear(redshift[i0],args[0],args[1])-distance[i0]\n", "        residualsw = np.append(residualsw,weights[i0]*pResid**2)\n", "    return residualsw\n", "\n", "residualsw = resid_w(linear,[Aw,bw],distance,weights)\n", "sumw=np.sum(weights)\n", "rsw=np.average(redshift,weights=weights)\n", "sigmaw=np.sum(residualsw)/(len(redshift)-2)\n", "VarAw=sigmaw*1./variance_w(redshift,weights)*1./sumw\n", "Varbw=VarAw*(rsw)**2+sigmaw/sumw\n", "    \n", "print(\"Weighted Hubbles Constant:\",1e6*3e5/Aw,\"+/-\",1e6*3e5*math.sqrt(VarAw)/Aw/Aw,\"intercept\",bw,\"+/-\",math.sqrt(Varbw))#Note 1e6 is from pc to Mpc and 3e5 is c in km/s\n", "print()\n", "\n", "#Now the previous\n", "print(\"Unweighted Hubbles Constant:\",1e6*3e5/A,\"+/-\",1e6*3e5*math.sqrt(VarA)/A/A,\"intercept\",b,\"+/-\",math.sqrt(Varb))#Note 1e6 is from pc to Mpc and 3e5 is c in km/s\n"]}, {"cell_type": "markdown", "id": "81f1cd36", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='exercises_5_3'></a>     \n", "\n", "| [Top](#section_5_0) | [Restart Section](#section_5_3) | [Next Section](#section_5_4) |\n"]}, {"cell_type": "markdown", "id": "49023cd8", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-5.3.1</span>\n", "\n", "Why is the weighted Hubble's constant different from the unweighted one? Select the best answer below:\n", "\n", "- Points with larger uncertainty pull on the fit-line more than points with smaller uncertainty.\n", "- Points with smaller uncertainty pull on the fit-line more than points with larger uncertainty.\n", "- It is impossible to know why the fit has changed.\n"]}, {"cell_type": "markdown", "id": "f3e26447", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-5.3.2</span>\n", "\n", "Compute the difference between the mean and the weighted mean to two significant digits; call this $\\Delta_{\\mathrm{Hubble}}$.\n", "\n", "Also compute the uncertainty of the difference of the two measurements; call this $\\sigma_{\\mathrm{tot}}$. Assume they are separate, uncorrelated measurements, thus add the uncertainties in quadrature, i.e.:\n", "\n", "$$\\sigma^2_{\\rm{tot}} = \\sigma^2_{1} + \\sigma^{2}_{2}$$\n", "\n", "Enter your answer as a list of numbers with precision 1e-2: [$\\Delta_{\\mathrm{Hubble}}$, $\\sigma_{\\mathrm{tot}}$]\n", "\n", "\n", "Are these variations consistent with each other? "]}, {"cell_type": "code", "execution_count": null, "id": "e08c1fd8", "metadata": {"tags": ["py", "draft", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L5.3.1\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n"]}, {"cell_type": "markdown", "id": "8711f587", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_5_4'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L5.4 Introduction to Likelihood</h2>  \n", "\n", "| [Top](#section_5_0) | [Previous Section](#section_5_3) | [Exercises](#exercises_5_4) | [Next Section](#section_5_5) |\n"]}, {"cell_type": "code", "execution_count": null, "id": "87e0b88c", "metadata": {"tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L5.4-slides\n", "\n", "from IPython.display import IFrame\n", "IFrame(src='https://mitx-8s50.github.io/slides/L05/slides_L05_04.html', width=970, height=550)"]}, {"cell_type": "markdown", "id": "9efeefd7", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='exercises_5_4'></a>     \n", "\n", "| [Top](#section_5_0) | [Restart Section](#section_5_4) | [Next Section](#section_5_5) |\n"]}, {"cell_type": "markdown", "id": "6eced2c1", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-5.4.1</span>\n", "\n", "What is the log likelihood evaluated at $p=40$%, given that you observe 56/100 people who claim they can smell asparagus after they pee?\n", "\n", "You can use the starting code below, if you wish.\n", "\n", "Report your answer with precision 1e-3."]}, {"cell_type": "code", "execution_count": null, "id": "92d7e40a", "metadata": {"tags": ["draft", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L5.4.1\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "def prob(p,nobs,ntrials):\n", "    #nobs: the number of positive observations\n", "    #ntrials: the total number of observations (trials)\n", "    return #YOUR CODE HERE\n", "\n", "print(\"Probability is \",prob(0.4,56,100))\n", "print(\"Log Likelihood is\", np.log(prob(0.4,56,100)))\n"]}, {"cell_type": "markdown", "id": "5e80dbbd", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": [">#### Follow-up 5.4.1a (ungraded)\n", ">\n", ">Plot the likelihood and log likelihood as a function of $p$, given the observation of a 56/100 result. Alternatively, plot the probability of attaining a given outcome vs. the number of positive outcomes (in other words, varying $x$, the number of positive results). How are these plots different?"]}, {"cell_type": "markdown", "id": "27ccd774", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_5_5'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L5.5 An Example: Auger Data (Part 1)</h2>  \n", "\n", "| [Top](#section_5_0) | [Previous Section](#section_5_4) | [Exercises](#exercises_5_5) | [Next Section](#section_5_6) |\n"]}, {"cell_type": "code", "execution_count": null, "id": "1589e5c4", "metadata": {"tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L5.5-slides\n", "\n", "from IPython.display import IFrame\n", "IFrame(src='https://mitx-8s50.github.io/slides/L05/slides_L05_05.html', width=970, height=550)"]}, {"cell_type": "code", "execution_count": null, "id": "03a2ed58", "metadata": {"tags": ["learner", "py", "lect_05", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L5.5-runcell01\n", "\n", "import numpy as np\n", "import csv\n", "import math\n", "import matplotlib.pyplot as plt\n", "\n", "\n", "#Let's say we have\n", "label='data/L05/events_a8_1space.dat'\n", "\n", "def rad(iTheta):\n", "    return iTheta/180. * math.pi\n", "\n", "def rad1(iTheta):\n", "    return iTheta/180. * math.pi-math.pi\n", "\n", "def exposure(dec):\n", "    theta_max = np.radians(60) # Maximum zenith angle in the dataset\n", "    l = np.radians(-35.23) # Latitude of the center of the array (near Malarg\u00fce - Argentina)\n", "    arg = (np.cos(theta_max) - np.sin(l)*np.sin(dec)) / (np.cos(l)*np.cos(dec))\n", "    hm = np.arccos(arg.clip(-1, 1))\n", "    return np.cos(l)*np.cos(dec)*np.sin(hm) + hm*np.sin(l)*np.sin(dec)\n", "\n", "def load(label):\n", "    dec=np.array([])\n", "    ra=np.array([])\n", "    az=np.array([])\n", "    with open(label,'r') as csvfile:\n", "        plots = csv.reader(csvfile,delimiter=' ')\n", "        for pRow in plots:\n", "            if '#' in pRow[0] or pRow[0]=='':\n", "                continue\n", "            dec = np.append(dec,rad(float(pRow[2])))\n", "            ra  = np.append(ra,rad1(float(pRow[3])))\n", "            az  = np.append(az,rad(float(pRow[4])))\n", "    return dec,ra,az\n", "\n", "\n", "dec,ra,az = load(label)\n", "\n", "#Let's make a plot this is in local coordinates\n", "color_map = plt.cm.Spectral_r\n", "fig = plt.figure(figsize=(20, 8))\n", "fig.add_subplot(111, projection='mollweide')\n", "w=exposure(dec) #correct for the exposure rate at the latitude of the observatory.\n", "image = plt.hexbin(ra, dec, cmap=color_map,gridsize=60, mincnt=1,C=w,reduce_C_function=np.sum)\n", "plt.xlabel('R.A.')\n", "plt.ylabel('Decl.')\n", "plt.colorbar()\n", "plt.grid(True)\n", "plt.show()\n", "\n", "#Now let's plot this in Galactic Coordinates\n", "from astropy.coordinates import SkyCoord\n", "from astropy import units\n", "from astropy.coordinates import Galactic\n", "\n", "coords = SkyCoord(ra=ra, dec=dec, unit='rad')\n", "rap = coords.galactic.l.wrap_at(180 * units.deg).radian\n", "decp = coords.galactic.b.radian\n", "\n", "color_map = plt.cm.Spectral_r\n", "fig = plt.figure(figsize=(20, 8))\n", "fig.add_subplot(111, projection='mollweide')\n", "image = plt.hexbin(rap, decp, cmap=color_map,gridsize=45, mincnt=1,reduce_C_function=np.sum)\n", "\n", "plt.xlabel('R.A.')\n", "plt.ylabel('Decl.')\n", "plt.grid(True)\n", "plt.colorbar(image, spacing='uniform', extend='max')\n", "plt.show()\n"]}, {"cell_type": "code", "execution_count": null, "id": "e40d6827", "metadata": {"tags": ["learner", "py", "lect_05", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L5.5-runcell02\n", "\n", "from scipy import stats\n", "\n", "def plotHist(iData,iNBins=30):\n", "    #Ok enough of having fun, let's look at the asymmetry we observe in right asecion\n", "    y0, bin_edges = np.histogram(iData, bins=iNBins)\n", "    bin_centers = 0.5*(bin_edges[1:] + bin_edges[:-1])\n", "    norm0=len(iData)*(bin_edges[-1]-bin_edges[0])/iNBins\n", "    plt.errorbar(bin_centers,y0/norm0,yerr=y0**0.5/norm0,marker='.',drawstyle = 'steps-mid',linestyle='none')\n", "    plt.xlabel(\"RA\")\n", "    plt.ylabel(\"Intensity\")\n", "    plt.show()\n", "    return bin_centers,y0\n", "\n", "print(len(ra))\n", "_,_ = plotHist(ra)"]}, {"cell_type": "markdown", "id": "5ac0a80d", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='exercises_5_5'></a>     \n", "\n", "| [Top](#section_5_0) | [Restart Section](#section_5_5) | [Next Section](#section_5_6) |\n"]}, {"cell_type": "markdown", "id": "3395c1cc", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-5.5.1</span>\n", "\n", "What is the range of declination (sky coordinates) available in the data (the data are given in units of radians).? Report your answer as a list of numbers, in units of radians, with precision 1e-3: `[dec_min, dec_max]`.\n", "\n", "Hint: This can be found with a single line of code.\n"]}, {"cell_type": "markdown", "id": "48fd236d", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-5.5.2</span>\n", "\n", "Now let's look at the variations in the intensity as a function of RA for a subset of the data with a certain range of declination. Specifically, select the data with declination above the equator and plot it. Complete the code below to do this.\n", "\n", "Do you see a trend similar to the one you see in $RA$? Select the best answer from the following:\n", "\n", "- Yes, the trend is even more clear\n", "- No, there is conclusively no trend\n", "- There might be a slight trend, but the uncertainties are too large to tell\n"]}, {"cell_type": "code", "execution_count": null, "id": "46b45631", "metadata": {"tags": ["draft", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L5.5.2\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "ranew=#YOUR Code here\n", "\n", "_,_ = plotHist(ranew)"]}, {"cell_type": "markdown", "id": "e8418788", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": [">#### Follow-up 5.5.2a (ungraded)\n", ">\n", ">Systematically explore different slices of the data within the range `[dec_min, dec_max]`. Are there any trends that you notice?"]}, {"cell_type": "markdown", "id": "7cdbdc39", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_5_6'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L5.6 An Example: Auger Data (Part 2)</h2>  \n", "\n", "| [Top](#section_5_0) | [Previous Section](#section_5_5) | [Exercises](#exercises_5_6) | [Next Section](#section_5_7) |\n"]}, {"cell_type": "code", "execution_count": null, "id": "5effe347", "metadata": {"tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L5.6-slides\n", "\n", "from IPython.display import IFrame\n", "IFrame(src='https://mitx-8s50.github.io/slides/L05/slides_L05_06.html', width=970, height=550)"]}, {"cell_type": "code", "execution_count": null, "id": "3b7f10c3", "metadata": {"tags": ["learner", "py", "lect_06", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L5.6-runcell01\n", "\n", "#Let's say we have\n", "NLeft=0\n", "NRight=0\n", "for i0 in range(len(ra)):\n", "    if ra[i0] < 0:\n", "        NLeft+=1\n", "    else:\n", "        NRight+=1\n", "print(\"NLeft:\",NLeft,\"+/-\",math.sqrt(NLeft),\"NRight:\",NRight,\"+/-\",math.sqrt(NRight),\"total/2\",len(ra)/2.)\n", "\n", "plotHist(ra,2)"]}, {"cell_type": "code", "execution_count": null, "id": "f7a86b11", "metadata": {"tags": ["learner", "py", "lect_06", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L5.6-runcell02\n", "\n", "def pvalues(NLeft,NRight):\n", "    #Let's compute it\n", "    lamb=(NLeft+NRight)/2. #average number of events\n", "    pleft=stats.poisson.pmf(NLeft,lamb) #probability of left given averge\n", "    pright=stats.poisson.pmf(NRight,lamb) #probability of right given averaged \n", "    pcheck=stats.poisson.pmf(int(lamb),lamb)#Most likely probability \n", "    print(\"Likelihood Ratio-left\",pleft/pcheck,\"Likelihood Ratio-right\",pright/pcheck,\"check\",pcheck/pcheck)\n", "pvalues(NLeft,NRight)"]}, {"cell_type": "markdown", "id": "c4fc36e8", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='exercises_5_6'></a>     \n", "\n", "| [Top](#section_5_0) | [Restart Section](#section_5_6) | [Next Section](#section_5_7) |\n"]}, {"cell_type": "markdown", "id": "21567cf0", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-5.6.1</span>\n", "\n", "Consider the analysis that we just performed, where we split the data into left and right RA. How many standard deviations is the count in the left bin, $N_{\\mathrm{left}}$, from the expected (or average) count, $N_{\\mathrm{avg}}$, assuming a uniform rate? Recall that $N_{\\mathrm{avg}}=16093.5$ and $N_{\\mathrm{left}} = 16600 \\pm 128.84$.\n", "\n", "Calculate the same number for the right bin, and report your answer as a list of two positive numbers `[num_stdev_left, num_stdev_right]`, with precision 1e-2."]}, {"cell_type": "code", "execution_count": null, "id": "2f29153c", "metadata": {"tags": ["draft", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L5.6.1\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "pass\n"]}, {"cell_type": "code", "execution_count": null, "id": "be73bb65", "metadata": {"tags": ["py", "learner_chopped", "draft"]}, "outputs": [], "source": ["#>>>PROBLEM: L5.6.2\n", "\n", "label_2='data/L05/events_a4_1space.dat'\n", "dec_2,ra_2,az_2=load(label_2)\n", "\n", "#compute asymmetry\n", "NLeft_2=0\n", "NRight_2=0\n", "\n", "#YOUR CODE HERE\n", "\n", "#PRINT THE COUNTS WITH UNCERTAINTY\n", "\n", "#PRINT THE PROBABILITY (LIKELIHOOD RATIO)\n", "\n", "#PLOT IT"]}, {"cell_type": "markdown", "id": "1cea8cf6", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_5_7'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L5.7 Log-Likelihood and Chi-square</h2>  \n", "\n", "| [Top](#section_5_0) | [Previous Section](#section_5_6) | [Exercises](#exercises_5_7) | [Next Section](#section_5_8) |\n"]}, {"cell_type": "code", "execution_count": null, "id": "17072013", "metadata": {"tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L5.7-slides\n", "\n", "from IPython.display import IFrame\n", "IFrame(src='https://mitx-8s50.github.io/slides/L05/slides_L05_07.html', width=970, height=550)"]}, {"cell_type": "code", "execution_count": null, "id": "e1cb212b", "metadata": {"tags": ["learner", "py", "lect_07", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L5.7-runcell00\n", "\n", "#For the purposes of this section, we will use the low energy data.\n", "#Load it here, where we will redefine dec, ra, and az\n", "\n", "label_2='data/L05/events_a4_1space.dat'\n", "dec,ra,az=load(label_2)"]}, {"cell_type": "code", "execution_count": null, "id": "882fa9a0", "metadata": {"tags": ["learner", "py", "lect_07", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L5.7-runcell01\n", "\n", "_,xis=plotHist(ra)\n", "\n", "#Now let's define the log of a Poisson distribution (see above)\n", "def logpoisson(lamb): #x is our lambda and y0 is our data\n", "    lTot=0\n", "    for xi in xis:\n", "        test = math.factorial(xi)\n", "        lTot = xi*np.log(lamb) - lamb  - math.log(test) + lTot\n", "    return -1.*lTot\n", "\n", "#Now lets take the mean of this distribution and compute labmda\n", "lamb=xis.mean()\n", "print(\"Log Likelihood\",logpoisson(lamb),\"Regular Likelihood\",np.exp(logpoisson(lamb)))\n", "x = np.linspace(lamb*0.75, lamb*1.55, 100)\n", "plt.xlabel(\"$\\lambda$\")\n", "plt.ylabel(\"$\\log(\\mathcal{L}(\\lambda))$\")\n", "plt.plot(x, logpoisson(x));\n", "\n", "#finally let's compute the minimum of this distribution\n", "from scipy import optimize as opt\n", "sol=opt.minimize_scalar(logpoisson, method='Brent')\n", "print(\"minimum found:\",sol,\"Mean:\",lamb.mean())"]}, {"cell_type": "markdown", "id": "bbc9390d", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_5_8'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L5.8 Minimizing</h2>  \n", "\n", "| [Top](#section_5_0) | [Previous Section](#section_5_7) | [Exercises](#exercises_5_8) | [Next Section](#section_5_9) |\n"]}, {"cell_type": "code", "execution_count": null, "id": "529c6d3b", "metadata": {"tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L5.8-slides\n", "\n", "from IPython.display import IFrame\n", "IFrame(src='https://mitx-8s50.github.io/slides/L05/slides_L05_08.html', width=970, height=550)"]}, {"cell_type": "code", "execution_count": null, "id": "f0a9400e", "metadata": {"tags": ["learner", "py", "lect_08", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L5.8-runcell01\n", "\n", "#Log likelihood of a gaussian distribution of our data from above\n", "def loggaus(lamb):\n", "    lTot=0\n", "    for xi in xis:\n", "        lTot = lTot+(0.5/(lamb+1e-5))*(xi-lamb)**2\n", "        lTot = lTot-0.5*np.log(math.pi*2*lamb)\n", "    return lTot\n", "\n", "#chi2 distribution of our data from above.  \n", "def chi2(lamb):\n", "    lTot=0\n", "    for xi in xis:\n", "        lTot = lTot+(1./(lamb+1e-10))*(xi-lamb)**2\n", "    return lTot\n", "\n", "\n", "lamb=xis.mean()\n", "print(\"Gaussian Likelihood at minimum\",loggaus(lamb),lamb,len(xis))\n", "print(\"chi2 value at minium\",chi2(lamb))\n", "\n", "x = np.linspace(lamb*0.75, lamb*1.55, 100)\n", "plt.plot(x, loggaus(x),label='gaus');\n", "plt.plot(x, chi2(x)/2.,label='chi2/2');\n", "plt.xlabel(\"$\\lambda$\")\n", "plt.ylabel(\"$\\log(\\mathcal{L}(\\lambda))$\")\n", "plt.legend(loc='lower right')\n", "plt.show()\n", "\n", "#Now let's minimize the two\n", "from scipy import optimize as opt\n", "sol1=opt.minimize_scalar(loggaus, method='Brent')\n", "print(\"Gaussian Minimum\",lamb.mean())\n", "sol2=opt.minimize_scalar(chi2, method='Brent')\n", "print(\"Chi2 Minimum\",lamb.mean())"]}, {"cell_type": "code", "execution_count": null, "id": "d58ef737", "metadata": {"tags": ["learner", "py", "lect_08", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L5.8-runcell02\n", "\n", "#Now let's look at our chi2 distribution and see how this compares\n", "x = np.linspace(0,80)\n", "chi2d=stats.chi2.pdf(x,30) # w0 bins\n", "plt.plot(x,chi2d,label='chi2')\n", "plt.axvline(chi2(lamb), c='red')\n", "plt.legend(loc='lower right')\n", "plt.xlabel(\"$\\chi^{2}(x)$\")\n", "plt.ylabel(\"p-value\")\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "id": "264048d8", "metadata": {"tags": ["learner", "py", "lect_08", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L5.8-runcell03\n", "\n", "def chi2min(ilamb):\n", "    minchi2=chi2(xis.mean())+1 #This is the minmum over the data\n", "    return chi2(ilamb)-minchi2\n", "\n", "lamb=xis.mean()\n", "sol1=opt.root_scalar(chi2min,bracket=[lamb, lamb*1.1],method='brentq')\n", "sol2=opt.root_scalar(chi2min,bracket=[lamb*0.9, lamb],method='brentq')\n", "print(sol1)\n", "print(sol2)\n", "print(\"sol1\",xis.mean()+math.sqrt(xis.mean()/len(xis)))\n", "print(\"sol2\",xis.mean()-math.sqrt(xis.mean()/len(xis)))\n", "\n", "\n", "minlog=chi2(lamb)\n", "x = np.linspace(lamb*0.995, lamb*1.005, 50)\n", "plt.plot(x, chi2(x),label='chi2');\n", "plt.axvline(sol1.root, c='red',label=\"$\\hat{\\lambda}\\pm1\\sigma$\")\n", "plt.axvline(lamb, c='blue',label=\"$\\hat{\\lambda}$\")\n", "plt.axvline(sol2.root, c='red')\n", "plt.legend(loc='lower right')\n", "plt.xlabel(\"$\\lambda$\")\n", "plt.ylabel(\"$\\log(\\mathcal{L}(\\lambda))$\")\n", "plt.show()"]}, {"cell_type": "markdown", "id": "17dc7864", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='exercises_5_8'></a>     \n", "\n", "| [Top](#section_5_0) | [Restart Section](#section_5_8) | [Next Section](#section_5_9) |\n"]}, {"cell_type": "markdown", "id": "0665f53d", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-5.8.1</span>\n", "\n", "Now if we treat $\\chi^2$ as that of a single variable with a variance of $1$ (i.e., for some $\\lambda$), we can write\n", "\n", "$$\n", "\\chi^{2} = \\left(\\frac{\\lambda -\\hat{\\lambda}}{\\sigma_{\\lambda}}\\right)^{2}\n", "$$\n", "\n", "where $\\hat{\\lambda}$ is the best fit and $\\sigma_{\\lambda}$ is the uncertainty in $\\lambda$.\n", "\n", "What is the $\\Delta \\chi^2$ value from the minimum $\\chi^{2}$ corresponding to two standard deviations in $\\lambda$ from the best fit $\\hat{\\lambda}$? Enter an integer number for your answer."]}, {"cell_type": "markdown", "id": "0e0e958e", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_5_9'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L5.9 Comparison Using lmfit</h2>     \n", "\n", "| [Top](#section_5_0) | [Previous Section](#section_5_8) | [Exercises](#exercises_5_9) |\n"]}, {"cell_type": "code", "execution_count": null, "id": "9d36633b", "metadata": {"tags": ["learner", "py", "lect_09", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L5.9-runcell01\n", "\n", "#solution\n", "label8='data/L05/events_a8_1space.dat'\n", "dec,ra,az=load(label8)\n", "nbins=30\n", "_,xis=plotHist(ra,nbins)\n", "\n", "#compute the mean over the bins\n", "lamb=xis.mean()\n", "\n", "#minimize it\n", "sol2=opt.minimize_scalar(chi2, method='Brent')\n", "print(\"chi2 minimized value\",lamb.mean())\n", "\n", "#Now let's look at our chi2 distribution and see how this compares\n", "x = np.linspace(0,80)\n", "chi2d=stats.chi2.pdf(x,nbins) # 30 bins\n", "plt.plot(x,chi2d,label='chi2')\n", "plt.axvline(chi2(lamb), c='red')\n", "plt.legend(loc='lower right')\n", "plt.show()\n", "\n", "#now let's plot the mimum and uncertainty\n", "sol0=opt.minimize_scalar(chi2, method='Brent')\n", "lamb=sol0.x\n", "sol1=opt.root_scalar(chi2min,bracket=[lamb, lamb*1.01],method='brentq')\n", "sol2=opt.root_scalar(chi2min,bracket=[lamb*0.99, lamb],method='brentq')\n", "print(sol0)\n", "print(sol1)\n", "print(sol2)\n", "print(\"sol1\",xis.mean()+math.sqrt(xis.mean()/len(xis)))\n", "print(\"sol2\",xis.mean()-math.sqrt(xis.mean()/len(xis)))\n", "\n", "minlog=chi2(lamb)\n", "x = np.linspace(lamb*0.99, lamb*1.01, 50)\n", "plt.plot(x, chi2(x),label='chi2');\n", "plt.axvline(sol1.root, c='red',label=\"$\\hat{\\lambda}\\pm1\\sigma$\")\n", "plt.axvline(lamb, c='blue',label=\"$\\hat{\\lambda}$\")\n", "plt.axvline(sol2.root, c='red')\n", "plt.legend(loc='lower right')\n", "plt.xlabel(\"$\\lambda$\")\n", "plt.ylabel(\"$\\log(\\mathcal{L}(\\lambda))$\")\n", "#plt.legend(loc='lower right')\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "id": "b1a5798b", "metadata": {"tags": ["learner", "py", "lect_09", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L5.9-runcell02\n", "\n", "import lmfit\n", "#Plot a constant function\n", "def f(x,a):\n", "    return a\n", "\n", "def prephist(iRA):\n", "    y0, bin_edges = np.histogram(iRA, bins=30)\n", "    x0 = 0.5*(bin_edges[1:] + bin_edges[:-1])\n", "    y0 = y0.astype('float')\n", "    return x0,y0,1./(y0**0.5)\n", "\n", "def plothist(iRA):\n", "    x,y,xweights=prephist(iRA)\n", "    model  = lmfit.Model(f)\n", "    p = model.make_params(a=1000)\n", "    result = model.fit(data=y,x=x, params=p, weights=xweights)\n", "    lmfit.report_fit(result)\n", "    print(result.params.items(),result.params[\"a\"].value)\n", "    plt.errorbar(x,y,yerr=y**0.5,c='black',marker='.',linestyle = 'None')\n", "    x = np.linspace(x[0],x[-1], 50)\n", "    y=np.array([])\n", "    for pX in x:\n", "        pOut=f(pX,result.params[\"a\"].value)\n", "        y=np.append(y,pOut)\n", "    plt.plot(x,y)\n", "    plt.xlabel(\"RA\")\n", "    plt.ylabel(\"$N_{events}$\")\n", "    plt.show()\n", "    \n", "label8='data/L05/events_a8_1space.dat'\n", "dec,ra8,az=load(label8)\n", "plothist(ra8)\n", "\n", "label4='data/L05/events_a4_1space.dat'\n", "dec,ra4,az=load(label4)\n", "plothist(ra4)\n"]}, {"cell_type": "code", "execution_count": null, "id": "c4656786", "metadata": {"tags": ["learner", "py", "lect_09", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L5.9-runcell03\n", "\n", "#Answer: \n", "print(\"Answer:\",stats.norm.cdf(0,1)*100,\"% Above the line\")\n", "print(\"Answer:\",stats.norm.cdf(0,1)*100,\"% Below the line\")"]}, {"cell_type": "code", "execution_count": null, "id": "ea4db3c0", "metadata": {"tags": ["learner", "py", "lect_09", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L5.9-runcell04\n", "\n", "def fnew(x,a,b):\n", "    pVal=b*np.sin(x)\n", "    return a+pVal\n", "\n", "label8='data/L05/events_a8_1space.dat'\n", "dec,ra8,az=load(label8)\n", "x,y,xweights=prephist(ra8)\n", "print(x,y)\n", "\n", "model  = lmfit.Model(fnew)\n", "p = model.make_params(a=1000,b=10)\n", "result = model.fit(data=y,x=x, params=p, weights=xweights)\n", "lmfit.report_fit(result)\n", "plt.figure()\n", "result.plot()\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "id": "7b3eec0f", "metadata": {"tags": ["learner", "py", "lect_09", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: L5.9-runcell05\n", "\n", "#Now let's look at our chi2 distribution and see how this compares\n", "x = np.linspace(0,80)\n", "chi2d=stats.chi2.pdf(x,40) # 40 bins\n", "plt.plot(x,chi2d,label='chi2')\n", "plt.axvline(result.chisqr, c='red')\n", "plt.legend(loc='lower right')\n", "plt.show()"]}, {"cell_type": "markdown", "id": "9483beec", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='exercises_5_9'></a>   \n", "\n", "| [Top](#section_5_0) | [Restart Section](#section_5_9) |\n"]}, {"cell_type": "markdown", "id": "d9abd50e", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-5.9.1</span>\n", "\n", "Repeat the preceding fit using the function: \n", "\n", "$$\n", "\\begin{equation}\n", " f(x) = a x + b \n", "\\end{equation}\n", "$$\n", "\n", "What is the $\\chi^{2}$ value? Enter a number with precision 1e-3.\n", "\n", "Given these results, which fit is better? "]}, {"cell_type": "code", "execution_count": null, "id": "4c1a75c2", "metadata": {"tags": ["draft", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>EXERCISE: L5.9.1\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n"]}], "metadata": {"celltoolbar": "Tags", "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}